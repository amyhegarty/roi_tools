#!/usr/bin/env python
"""The run script."""
# Import packages
import pandas as pd
import numpy as np
import nilearn.image
import nilearn.plotting
from nilearn.image import index_img, iter_img
import sys, subprocess, os, datetime, logging
from nibabel.funcs import concat_images, four_to_three
import nibabel as nib
from pathlib import Path
from os.path import splitext

logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')
log = logging.getLogger(__name__)

# set version
__version__ = "0.0.1"


# define functions here...

def parser(context):
    # parse inputs similarly to cli ingest bids function

    def _path_exists(path, parser):
        """Ensure a given path exists."""
        if path is None or not Path(path).exists():
            raise parser.error(f"Path does not exist: <{path}>.")
        return Path(path).absolute()

    def _is_file(path, parser):
        """Ensure a given path exists and it is a file."""
        path = _path_exists(path, parser)
        if not path.is_file():
            raise parser.error(f"Path should point to a file (or symlink of file): <{path}>.")
        return path

    def _is_decimal(val, parser):
        """Ensure a given value is a value between 0 and 1."""
        val = float(val)
        if val < 0 or val > 1:
            raise parser.error(f"Entered value must be between 0 and 1")
        return val

    parser = argparse.ArgumentParser(
        description="Overlap Mapping Code is a tool used to set custom thresholds for a set of nifti images. Subject specific thresholds are generated by first setting a common critera for all images, then applying a custom threshold.",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )

    PathExists = partial(_path_exists, parser=parser)
    IsFile = partial(_is_file, parser=parser)
    IsDecimal = partial(_is_decimal, parser=parser)

    ##########################
    #   Required Arguments   #
    ##########################
    parser.add_argument(
        "input-path",
        action="store",
        metavar="PATH",
        type=PathExists,
        help="path to input 3D or 4D files to threshold"
    )
    parser.add_argument(
        "output-path",
        action="store",
        metavar="PATH",
        type=PathExists,
        help="path to output directory location for results"
    )

    ##########################
    #   Optional Arguments   #
    ##########################
    parser.add_argument(
        "--quantile",
        action='store',
        type=IsDecimal,
        help="Use a quantile (or % voxels) as the image threshold (values should be entered between 0-1)")
    parser.add_argument(
        "--mask",
        action="store",
        metavar="PATH",
        type=IsFile,
        help="path to 3D nifti image mask used to restrict threshold calculation"
    )
    parser.add_argument(
        "--dilate-kernel-type",
        action="store",
        help="specify kernel type used to dilate the boarder of provided mask [options: 3D, 2D, gaus,...]"
    )
    parser.add_argument(
        "--dilate-kernel-size",
        action="store",
        default=0,
        help="specify kernel size used to dilate the boarder of provided mask"
    )
    parser.add_argument("-v", "--verbosity", action="count", default=0)

    args = parser.parse_args()

    if args.dilate_kernel_type and (args.mask is None):
        parser.error("--dilate-kernel-type must be defined with --mask")
    elif args.dilate_kernel_size and (args.mask is None):
        parser.error("--dilate-kernel-size must be defined with --mask")
    elif args.dilate_kernel_type and (args.dilate_kernel_size is None):
        parser.error("--dilate-kernel-type and --dilate-kernel-size must be used together to define dilate kernel")

    # add all args to context
    args_dict = args.__dict__
    context.update(args_dict)

    ##########################
    #    Argument Checks     #
    ##########################

    # check input-path and mask are both nifti image types
    if context["input_path"].isdir():
        # assume if directory is passed you are looking for filtered_func_data.nii.gz
        context["input_path"] = context["input_path"] / "filtered_func_data.nii.gz"
        if not context["input_path"].exists():
            parser.error("Input path: %s not found.", str(context["input_path"]))
    if context["input_path"].isfile():
        if ".nii" not in context["input_path"]:
            parser.error("Input path: %s must be nifti file.", str(context["input_path"]))

    if args.mask:
        if ".nii" not in context["mask"]:
            parser.error("Mask path: %s must be nifti file.", str(context["mask"]))

    # end parser


def main(context):
    """Entry point."""

    # parse user inputs and store in context
    parser(context)

    # load in input image
    img = nilearn.image.load_img(context["input_path"])
    data = nilearn.image.get_data(img)

    #initialize values
    new_data = np.zeros(img.shape)
    upper_thres = []
    lower_thres = []

    # if mask exists load it and dilate
    if context.has_key("mask"):
        mask = dilatemask(context["mask"])

    for i in range(0, nimgs - 1):
        # pull each 3D image separately
        idx_data = data[:, :, :, i]

        # apply mask
        # TODO MAKE SURE MASK IS BIANARY THEN MASK INPUT DATA
        if mask:
            idx_data = idx_data .* mask

        # compute threshold
        thres_pos, thres_neg = computethreshold(idx_data,context["method"],context["threshold"])

        # apply threshold
        thres_idx_data = data[:, :, :, i]
        idx_data[np.logical_and(idx_data <= thres_pos, idx_data >= thres_neg)] = 0

        # store data for output
        new_data[:, :, :, i] = idx_data
        upper_thres.append(thres_pos)
        lower_thres.append(thres_neg)

    # save outputs to file, start by pulling together single objects for file writing
    df = pd.DataFrame.from_dict({'upper': upper_thres, 'lower': lower_thres})

    # create new output image
    results_img = nib.nifti1.Nifti1Image(new_data, affine=img.affine.copy(), header=img.header.copy())

    # save outputs
    saveoutputs(context["output_path"],results_img,df)


def computethreshold(arr,method,stat):
    """Compute the threshold for a 3D image, based on provided method (e.g. quantile), and threshold stat

    Args:
        arr (3D numpy array): image data used to compute a method based threshold (e.g. quantile)
        method (str): method to apply, currently only support "quantile"
        stat (float): value used with the method described above to set custom image threshold
    """

    if method.lower() is "quantile":
        thres_pos = np.quantile(arr[arr > 0], stat)
        thres_neg = -np.quantile(np.abs(arr[arr < 0]), stat)
    else:
        log.error("Currently only quantile based thresholding is supported. Come back later!")

    return [thres_pos, thres_neg]

def saveoutputs(context,outimage, outcsv):
    # set output path and filenames
    suffix = "_Q"+str(context["threshold"]) +".nii.gz"
    outputfilename = splittext(context["input_path"].basename())[0].with_suffix(suffix)
    path = context["output_path"]

    # write outputs to a predetermined location...
    os.system('mkdir -p ' + os.path.dirname(path))
    outimage.to_filename(os.path.join(str(path),outputfilename))
    log.info('Result image saved: %s', os.path.join(str(path),outputfilename))

    # write threshold values also
    outcsv.to_csv(os.path.join(str(path),outputfilename.replace('.nii.gz', '.csv')))
    log.info('Thresholds used stored %s', os.path.join(str(path),outputfilename.replace('.nii.gz', '.csv')))

def dilatemask(context, mask):

    return new_mask

# Only execute if file is run as main, not when imported by another module
if __name__ == "__main__":  # pragma: no cover

    pycontext = dict()

    # Create client, using CLI credentials
    pycontext['fw'] = flywheel.Client()

    # who am I logged in as?
    log.info('You are now logged in as %s to %s', pycontext['fw'].get_current_user()['email'],
             pycontext['fw'].get_config()['site']['api_url'])

    main(pycontext)
    # 1. parse inputs (perform necessary checks, eg path exists, sub / ses exist)

    # 2. check upload level (project, subject, session)

    #    2a. ignore project level for now (return error)
    #    2b. subject/session level -> run.py?

    # run.py
    # pull correct flywheel session
    # check if analysis exists -- if so look for "allow-multiples" (error if allow-multiples = false)
    # look for logs, analysis_configuration.txt, analysis_information.txt, run_script[.sh,.zip]
    # if any not present, fail
    # set (and check) basepath, fmiprep_zip_path, temp_uploads path

    # run zipping for output folder (and logs if necessary)
    # zip report html
    # create new analysis and upload all files
    # check upload sucsess (checksum - TODO, datasize)
